JavaScript is disabled on your browser. Please enable JavaScript to use all the features on this page. Skip to main content Skip to article
Elsevier logo ScienceDirect

    Journals & Books

Register Sign in
Brought to you by: Copenhagen University Library
Sign in Register

    Journals & Books

    Help

Brought to you by
Copenhagen University Library
Change organization
 
Outline
Download PDF Download
Share
Export
Advanced
Outline

    Highlights
    Existing behavioral field research on dishonesty
    Methodological approaches: field experiments and archival
    Measuring dishonest behavior
    Other identification challenges in archival work
    The promise of mixed methods
    Conclusion
    References and recommended reading
    References

Show full outline
Elsevier
Current Opinion in Psychology
Volume 6 , December 2015, Pages 70-76
Current Opinion in Psychology
Behavioral field evidence on psychological and social factors in dishonesty and misconduct
Author links open overlay panel Lamar Pierce Parasuram Balasubramanian
Show more
https://doi.org/10.1016/j.copsyc.2015.04.002 Get rights and content
Highlights

•

    We review behavioral field evidence on dishonesty from social and behavioral sciences.
•

    We explain value of complementing lab research with behavioral field evidence.
•

    We review methods of archival analysis, natural experiments, and randomized natural field experiments.
•

    We clarify challenges of causality and alternative explanations unique to field data.

We review recent behavioral field evidence on dishonesty and other unethical behaviors from psychology and related fields. We specifically focus on individual-level studies that use explicitly behavioral data in natural settings, covering research topics relevant to psychology from across disciplines. Our review shows both the paucity and potential of behavioral field evidence on the psychology of dishonesty — although such research can provide actionable and realistic conclusions, it presents a host of practical and identification-related challenges that have limited its use. We explain the major methodological approaches, and discuss the multiple identification challenges for researchers using archival and other non-experimental data.

    Previous article in issue
    Next article in issue

Current Opinion in Psychology 2015, 6 :70–76

This review comes from a themed issue on Morality and ethics

Edited by Francesca Gino and Shaul Shalvi

For a complete overview see the Issue and the Editorial

Available online 22nd April 2015

http://dx.doi.org/10.1016/j.copsyc.2015.04.002

2352-250X/© 2015 Elsevier Ltd. All rights reserved.

Laboratory research on dishonesty and other unethical and illicit behaviors has proven invaluable in helping to understand the behavioral underpinnings of misconduct. Similarly, survey-based studies have provided a wealth of data and insights on self-reported dishonesty as well as its motivations, mechanisms, and prevalence. Yet an emerging stream of research is using behavior data from field experiments, direct observation, and archival sources to address concerns about the generalizability of often low-stakes laboratory studies and potentially biased self-reported data. This review details the current state of this emerging literature in psychology and related fields, and provides guidelines for future research. We focus specifically on studies that use individual-level behavioral data from ‘natural’ settings — those where people engage in their typical work or personal activities. Related reviews on organizational-level misconduct [ 1 ] and broader literatures in business and behavioral ethics [ 2 , 3 ] are also valuable reading.
Existing behavioral field research on dishonesty

We first review the existing behavioral field research on topics of interest to psychologists and behavioral scientists.
Social processes

One of the most promising and important topics on dishonesty is how social processes influence behavior, with a growing body of work using behavioral field evidence to explore it. Bucciol et al . [ 4 ] used direct observation and interviews to identify how bus passengers traveling with family members were more likely to have a valid ticket, but not those traveling with friends. Similarly, a field experiment on customers keeping excessive change in Israeli restaurants found almost no improved honesty from groups, with the higher average honesty of women exerting little pressure on their male dining companions [ 5 • ]. These results suggest that social pressure may selectively increase honesty, but that the specific social dynamics are crucial. Two recent studies of performance enhancing drugs in baseball [ 6 ] and cycling [ 7 ] show that social and professional interactions are crucial in disseminating both knowledge and acceptance of illicit drug usage. These follow an important early study of social processes in sports cheating, where Duggan and Levitt [ 8 • ] showed that sumo wrestlers reciprocally throw matches to aid one another in achieving a minimum win count. It is also consistent with recent work using communication data to examine information transmission among networks of dishonest parties [ 9 , 10 ]. This is consistent with a field experiment by Wenzel [ 11 • ] that found information on others’ behavior improved tax compliance, as well as results showing employees become more dishonest when joining dishonest firms [ 12 ].
Fairness, equity, and social comparison

Social comparison and related fairness and equity concerns are also a focus of recent work. Early work by Greenberg [ 13 •• ] was one of the first to address this topic using behavioral field data, showing increased theft following a pay decrease at two out of three factories. A related study [ 14 ] also showed higher theft when the employer, not coworkers, was the likely victim. A notable recent study by Edelman and Larkin [ 15 •• ] found social comparison as a motivation among faculty fraudulently downloading their own papers on SSRN. Related to social comparison is a small set of field studies on socioeconomic class and dishonesty. Although Gino and Pierce [ 16 •• ] found evidence of dishonest helping within socioeconomic class in mechanics, Balafoutas et al . [ 17 • ] find no differences in fraud by taxi drivers across customer income levels. Related work [ 18 ] examines the socioeconomic class of aggressive drivers, although mechanisms linking dishonesty with personal wealth are difficult to separate.
Moral reminders and preferences

Multiple large-scale field experiments have focused on testing the efficacy of moral reminders previously established in laboratory studies. Studies of individual taxpayers [ 19 ] and newspaper buyers [ 20 • ] found that the inclusion of a moral reminder increased honesty in disclosures and payments. In contrast, a field experiment by Fellner et al . [ 21 • ] found that Austrians only improved their honesty in paying TV licensing fees when mailed threats of enforcement, not when sent moral appeals. These build on an earlier important study of bagel customers by Levitt [ 22 ], who found that payments under the honor system were largely a function of internal moral preferences. Furthermore, he found that the September 11 terrorist attack significantly increased honesty in payments, suggesting the power of moral reminders. Related to this, Shu et al . [ 23 •• ] used a field experiment to show that insurance customers who signed at the top of forms reported higher annual mileage than those who signed at the bottom, presumably because signing provided a moral reminder.
Culture

Several recent studies have also found the influence of ethnic or national culture and identity on dishonest behavior. A foundational study in economics correlated national corruption measures with the unpaid parking tickets of diplomats [ 24 •• ]. Other papers focused on how interactions within and across ethnic and national groups can change levels of dishonesty, including favoritism in Olympic judging [ 25 ], ethnic diversity and corruption in Indonesia [ 26 ], and stock market fraud in Kenya [ 27 •• ]. One approach by Bianchi and Mohliver [ 28 ] links economic conditions during executives’ formative periods to stock option backdating.
Professionalism

One growing area of interest is how the professional identity and pro-social motivation of an expert can clash with her career and financial incentives. Although dishonesty in certain professions might be expected (e.g., auto mechanics) [ 29 ], for others the public's trust in expert honesty is crucial. Medicine provides several examples, such as how liver transplant surgeons’ financial and prosocial motivations can lead to dishonest patient reporting [ 30 •• ]. Similarly, teachers who are expected to instill ethical values in children have been shown to cheat when pressured with strong financial and career incentives [ 31 • ].
Incentives and control

One of the largest bodies of behavioral field studies centers on extrinsic motivation from incentives and control — how financial payoffs, monitoring, and penalties can alter dishonest behavior. Although the majority of this work is in economics [ 32 ], the work on monitoring has particular implications for psychological theories of dishonesty. Monitoring, for example, has been shown to reduce theft [ 33• , 34• ], unexcused absenteeism [ 35 • ], and dishonest reporting [ 36 ] in organizational settings such as call centers, restaurants, schools, and banks. Similarly, recent field experiments have targeted tax fraud [ 37 , 38 ] and corruption [ 39• , 40 ] through the explicit manipulation of increased monitoring through audits and transparency. Although economic theory implies the efficacy of monitoring, evidence from a field experiment on factory productivity monitoring [ 41 ] suggests that psychological mechanisms may make monitoring counterproductive in reducing dishonesty. Behavioral field research that can test the multiple psychological and economic mechanisms invoked by monitoring is clearly needed.
Methodological approaches: field experiments and archival

Three principal methodological approaches dominate behavioral field research on dishonesty: direct observation, randomized field experiments, and archival data analysis. Direct observation involves actively observing and recording behavior under multiple conditions to infer relationships between dishonesty and environmental conditions or individual differences. This method lacks the randomized manipulation of a field experiment, and observation is typically covert to avoid Hawthorne effects. The broad and random sampling of both honest and dishonest behavior across conditions and differences is important to avoid selection bias. Examples include researchers actively watching and recording problematic behavior such as illegal parking [ 42 ], bus fare evasion [ 4 ], aggressive driving [ 18 ], or bribes paid by truckers in Indonesia [ 43 ].

Field experiments typically involve direct observation, but also include random assignment of manipulations to treatment and control groups, as in laboratory experiments. Although highly stylized experiments outside of a laboratory are often considered to be ‘field experiments,’ those conducted in natural behavioral settings are most valuable for understanding behavior in the field. Such ‘natural field experiments’ study individuals in plausibly normal daily behavior, rather than in contrived tasks or jobs they would not normally do. Random assignment can occur either as individuals [ 23 •• ] or groups [ 20 • ]; field settings often make individual randomization impossible for practicality reasons or because of the inseparability of organizational or social settings. The strengths of natural field experiments on dishonesty are threefold: they are immediately generalizable to specific social or organizational settings, they provide strong causal inference, and they frequently provide immediate and measurable policy implications for managers or government.

The third methodological approach is the analysis of archival behavioral field data. Archival data on dishonesty can be easier to acquire than opportunities for true field experiments or even observational data, particularly in organizational settings where management can be reluctant to allow researchers to manipulate or interact with the work environment. Archival data present several important identification challenges, however, because of the lack of random assignment. Causality is therefore difficult to establish because of selection bias and often cross-sectional data structure. Just as commonly, omitted variables might explain the relationship between the variable of interest and dishonesty in a way inconsistent with the proposed theoretical explanation. Researchers therefore often rely on ‘natural experiments’ — exogenous shocks to some individuals or groups that can create quasi-treatment and control groups, such as exogenous restaurant monitoring technology implementation [ 33 • ].
Measuring dishonest behavior

One of the great challenges of studying dishonesty in the field is measurement precision and accuracy. Dishonesty and other forms of misconduct are intentionally committed under a veil of secrecy, due to explicit costs from detection and punishment. This yields two substantial problems in empirical work. First, measures of dishonesty will be inherently imprecise, with low observability rates across subjects and conditions. So long as this observability is randomly generated, it serves only as noise in any empirical model, and does not bias any results. The second and larger problem is when the observability of dishonesty is correlated with some other factor, such as individual competence, and is thus inaccurate and biased. This most commonly occurs because dishonest acts are rarely randomly detected and recorded. Instead, the actual detection of dishonest behavior is usually endogenous to any model of behavior. When we observe data on detected dishonesty, it reflects many observations of false negatives, and these false negatives almost certainly reflect their own psychological and economic processes.

Given these measurement challenges, there are several ways in which researchers typically measure dishonesty using behavioral field data. The simplest is to directly observe the behavior, either by the researcher or recorded in an archival data set. Jin and Kato [ 44 ] provide an excellent example through a field experiment purchasing baseball cards on eBay — the comparison of reported versus true condition directly measures dishonesty. Pierce and Snyder [ 45 • ] provide an example from archival data, observing revenue theft by workers in point-of-sales data from a large set of restaurants.

The second common method is to identify suspicious patterns of behavior that are inconsistent with the known counterfactual of honest behavior. Although this measurement strategy does not allow researchers to precisely identify individual dishonest acts, it provides probabilistic measures that still allow for hypothesis testing. Jacob and Levitt [ 31 • ] provide a classic example of this through suspicious answer patterns that identify teacher cheating. Pierce and Snyder's [ 12 , 45• ] use of improbably high pass rates from vehicle emissions testing experts provide a good example of fraud in a firm setting. Within academia, Simonsohn [ 46 •• ] and colleagues [ 47 ] provide clear examples of how counterfactual probability distributions of hypothesis tests can help identify both intentional and subconscious dishonesty in data reporting. This measurement method can be particularly useful in the context of a field experiment, where a manipulation that should only affect dishonest people (such as the risk of a tax audit) can impact reported income and deductions [ 19 , 33• , 38 ].
Other identification challenges in archival work
Addressing alternative explanations

Although field data may show patterns consistent with the theoretical explanation advanced by researchers, they carry an additional challenge endemic to non-experimental approaches — alternative explanations for observed correlations. In a tightly controlled laboratory setting, one can precisely manipulate the variable of interest, and thereby hold all other factors constant. But in a field setting, such precision is rarely possible, and identification can be haunted by multiple plausible or even probable alternative explanations for the results. Convincing archival and observational studies of dishonesty must not only provide proof for a hypothesis, but must also cast substantial doubt on alternative hypotheses.

Most significantly, causality is often difficult to establish, and researchers must be careful not to infer a causal relationship from correlational results. Even panel data, where multiple individuals are observed across time, often is unable to reveal causal evidence because of independent variables that are endogenously determined. One promising approaches is to exploit a natural experiment, where the impact of plausibly exogenous shock on individual behavior can be reasonably called causal [ 20• , 22 , 33• ]. Another is to exploit discontinuous policy or rules through the equivalent of a quasi-experimental regression discontinuity design [ 8• , 30•• , 48 ].

In many field settings, alternative hypotheses cannot be fully dispelled, and the scope of identification problems must be weighed against the novelty of the research question and field setting. Yenkey's [ 27 •• ] study of ethnicity and stock market fraud in Kenya, for example, is exceptionally novel on both dimensions. In all cases, researchers should be, and should be encouraged by editors to be, honest about identification problems in their research.
Identifying psychological (and economic) mechanisms

Perhaps the biggest challenge with behavioral field data is the identification of specific psychological and economic mechanisms driving dishonest behavior. Theory may propose multiple mechanisms that could explain observed behavior, yet without the benefit of a controlled experimental setting, separating these mechanisms can be tricky. Behavioral field data are rarely accompanied by the self-response data frequently used by psychologists to measure psychological processes. Consequently, researchers must instead attempt to identify mechanisms either by using variation in the main effect through moderators.
The promise of mixed methods

One promising approach to addressing limitations in behavioral field data on dishonesty is to combine them with laboratory studies or surveys, particularly for the purpose of identifying specific psychological or economic mechanisms [ 15•• , 16•• , 18 , 20• ]. Researchers can test competing hypothesized mechanisms in controlled laboratory settings, but must be careful that both the experimental design and subject pool can be reasonably generalized to the field data setting. This is particularly important when the field setting involves experts with long-run reputational or incentive concerns, which may match poorly to undergraduate students playing highly stylized, low-stakes cheating games. Although scenario studies can help target the specific setting, subjects may not have the expertise and setting-specific knowledge to provide insights on the mechanisms behind observed behavior in the field. Similarly, surveys can help explicate the decision-making process and emotions, particularly when directly conducted with the population from which the behavioral field data were drawn.
Conclusion

Behavioral field research presents great opportunities for better understanding the psychological and economic foundations of dishonesty, yet they present their own set of unique challenges. The lack of randomized assignment in archival and observational data presents arguably the great challenge because they make causality difficult to establish and alternative explanations hard to dispel. Consequently, researchers must approach behavioral field data with an appropriate level of skepticism, and with the fundamental question of ‘what else might explain these results?’ Results that are consistent with a theory are not sufficient, because they produce false positive conclusions that are particularly dangerous in settings involving dishonesty. Instead, results should ideally be consistent with a theory and inconsistent with alternative theories for observed relationships.

The behavioral field studies discussed here are somewhat arbitrarily bounded by necessity, and are part of a much broader set of field studies on dishonesty. For example, survey-based studies can be extremely valuable to researchers, particularly when embedded in a randomized experimental design [ 49 ].

Given the rapidly expanding literature of laboratory studies on cognitive biases in ethical decision-making, there is a tremendous need for further behavioral field evidence on bias in dishonesty. A few recent studies address this shortage using data from banks [ 50 ] and illegal parking [ 42 ], but also demonstrate the difficulty of separating cognitive bias mechanisms from others in field data. Perhaps most promising is recent work by Rees-Jones [ 51 •• ] that uses a quasi-experimental regression discontinuity approach to identify how loss aversion influences tax fraud. Further field studies that can directly identify cognitive biases would provide a substantial contribution to the field of behavioral ethics.

Finally, behavioral field data on dishonesty bring additional risks and concerns regarding human subjects protection. Identifiable and private data on dishonesty have the potential to produce substantial harm, such as job loss, social shame, and even incarceration. Furthermore, field experiments must be typically limited to interventions believed to decrease dishonesty because of the potential cost to subjects and other parties.
References and recommended reading

Papers of particular interest, published within the period of review, have been highlighted as:

    • of special interest

    •• of outstanding interest

Recommended articles Citing articles (0)
Copyright © 2015 Elsevier Ltd. All rights reserved.
Recommended articles
No articles found.
Citing articles
Loading…
Article Metrics
View article metrics
Elsevier logo

    About ScienceDirect
    Remote access
    Shopping cart
    Advertise
    Contact and support
    Terms and conditions
    Privacy policy

We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the use of cookies .

Copyright © 2020 Elsevier B.V. or its licensors or contributors. ScienceDirect ® is a registered trademark of Elsevier B.V.

ScienceDirect ® is a registered trademark of Elsevier B.V.
